{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Bunraku Full (On-/Off-line) Collection \n",
    "__Data Transformation SQL CSVs -> JSON__\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Data files to generate:\n",
    "\n",
    "- __authors: 123__\n",
    "- __characters: 2,107__ — 17,006 images\n",
    "- __images: 21268__\n",
    "- __kashira: 129__ — 17,019 images\n",
    "- __performances: 931__ — 18,533 images\n",
    "- __performers: 184__ — 14,893 images\n",
    "- __plays: 178__ — 18,791 images\n",
    "- __productions: 293__ — 18,750 images\n",
    "- __pscenes: 2,609__ — 18,000 images\n",
    "- __spucks: 16,625__\n",
    "- __tags: 76__ — 8,941 images\n",
    "\n",
    "\n",
    "\n",
    "# Setup\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',1000)\n",
    "pd.set_option('max_seq_items','none')\n",
    "pd.set_option('display.max_colwidth',50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import data as dtype=object to avoid NaN/Float conversion of IDs\n",
    "authors = pd.read_csv('in/authors.csv', dtype=object)\n",
    "characters = pd.read_csv('in/characters.csv', dtype=object)\n",
    "images = pd.read_csv('in/allimages.csv', dtype=object)\n",
    "kashira = pd.read_csv('in/kashira.csv', dtype=object)\n",
    "performances = pd.read_csv('in/performances.csv', dtype=object)\n",
    "performers = pd.read_csv('in/performers.csv', dtype=object)\n",
    "plays = pd.read_csv('in/plays.csv', dtype=object)\n",
    "productions = pd.read_csv('in/productions.csv', dtype=object)\n",
    "pscenes = pd.read_csv('in/scenes_productions.csv', dtype=object)\n",
    "scenes = pd.read_csv('in/scenes.csv', dtype=object)\n",
    "shamisenplayers = pd.read_csv('in/sceneshamisens.csv', dtype=object)\n",
    "musicians = pd.read_csv('in/scenekotokokyus.csv', dtype=object)\n",
    "narrators = pd.read_csv('in/scenetayus.csv', dtype=object)\n",
    "spucks = pd.read_csv('in/spucks.csv', dtype=object)\n",
    "tags = pd.read_csv('in/tags.csv', dtype=object)\n",
    "# import + drop duplicates on join tables\n",
    "authors_plays = pd.read_csv('in/authors_plays.csv', dtype=object).drop_duplicates()\n",
    "characters_images = pd.read_csv('in/characters_images.csv', dtype=object).drop_duplicates()\n",
    "characters_plays = pd.read_csv('in/characters_plays.csv', dtype=object).drop_duplicates()\n",
    "kashira_images = pd.read_csv('in/kashira_images.csv', dtype=object).drop_duplicates()\n",
    "kashira_plays = pd.read_csv('in/kashira_plays.csv', dtype=object).drop_duplicates()\n",
    "performances_images = pd.read_csv('in/performances_images.csv', dtype=object).drop_duplicates()\n",
    "performers_images = pd.read_csv('in/performers_images.csv', dtype=object).drop_duplicates()\n",
    "plays_images = pd.read_csv('in/plays_images.csv', dtype=object).drop_duplicates()\n",
    "productions_images = pd.read_csv('in/productions_images.csv', dtype=object).drop_duplicates()\n",
    "scenes_images = pd.read_csv('in/scenes_images.csv', dtype=object).drop_duplicates()\n",
    "tags_images = pd.read_csv('in/tags_images.csv', dtype=object).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = authors.merge(authors_plays.groupby('author_id')['play_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add  plays\n",
    "characters = characters.merge(characters_plays.groupby('character_id')['play_id'].apply(list).reset_index(), how='left')\n",
    "# add images\n",
    "characters = characters.merge(characters_images.groupby('character_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "characters = characters.drop('character_code',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add characters\n",
    "images = images.merge(characters_images.groupby('image_id')['character_id'].apply(list).reset_index(), how='left')\n",
    "# add kashira\n",
    "images = images.merge(kashira_images.groupby('image_id')['kashira_id'].apply(list).reset_index(), how='left')\n",
    "# add performances\n",
    "images = images.merge(performances_images.groupby('image_id')['performance_id'].apply(list).reset_index(), how='left')\n",
    "# add performers\n",
    "images = images.merge(performers_images.groupby('image_id')['performer_id'].apply(list).reset_index(), how='left')\n",
    "# add plays\n",
    "images = images.merge(plays_images.groupby('image_id')['play_id'].apply(list).reset_index(), how='left')\n",
    "# add productions\n",
    "images = images.merge(productions_images.groupby('image_id')['production_id'].apply(list).reset_index(), how='left')\n",
    "# add scenes\n",
    "images = images.merge(scenes_images.groupby('image_id')['pscene_id'].apply(list).reset_index(), how='left')\n",
    "# add tags\n",
    "images = images.merge(tags_images.groupby('image_id')['tag_id'].apply(list).reset_index(), how='left')\n",
    "\n",
    "images = images[['image_id','media_type','character_id','tag_id','kashira_id','performance_id','performer_id','play_id','production_id','pscene_id','container','container_type','creator','item_id','colser_id','notes','objid','sequence','series','slidepage_folder']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kashira (puppets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add images\n",
    "kashira = kashira.merge(kashira_images.groupby('kashira_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "# add plays\n",
    "kashira = kashira.merge(kashira_plays.groupby('kashira_id')['play_id'].apply(list).reset_index(), how='left')\n",
    "\n",
    "kashira = kashira[['kashira_id','label_eng','label_ka','category','image_id','play_id','sort_ja']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (P)Scenes (at performance level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels and scene_order\n",
    "scenes = scenes[['scene_id','label_eng','label_ja','label_ka','scene_order']]\n",
    "pscenes = pscenes.drop('spuck_note',1).drop('tayu_shamisen_note',1)\n",
    "pscenes = pscenes.merge(scenes, how='left')\n",
    "# add spuck_id\n",
    "pscenes = pscenes.merge(spucks.groupby('pscene_id')['spuck_id'].apply(list).reset_index(), how='left')\n",
    "# drop narrator with id 0 (no such performer exists)\n",
    "narrators = narrators[narrators['narrator_id'] != '0']\n",
    "# add narrator_ids\n",
    "pscenes = pscenes.merge(narrators.groupby('pscene_id')['narrator_id'].apply(list).reset_index(), how='left')\n",
    "# add musician_ids\n",
    "pscenes = pscenes.merge(musicians.groupby('pscene_id')['musician_id'].apply(list).reset_index(), how='left')\n",
    "# add shamisen_ids\n",
    "pscenes = pscenes.merge(shamisenplayers.groupby('pscene_id')['shamisen_id'].apply(list).reset_index(), how='left')\n",
    "# add image_ids\n",
    "pscenes = pscenes.merge(scenes_images.groupby('pscene_id')['image_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances =  performances.drop('data_id',1).drop('code',1)\n",
    "# add images\n",
    "performances = performances.merge(performances_images.groupby('performance_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "# add pscenes\n",
    "performances = performances.merge(pscenes.groupby('performance_id')['pscene_id'].apply(list).reset_index(), how='left')\n",
    "# add characters from play_id\n",
    "performances = performances.merge(characters_plays.groupby('play_id')['character_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors\n",
    "plays = plays.merge(authors_plays.groupby('play_id')['author_id'].apply(list).reset_index(), how='left')\n",
    "# characters\n",
    "plays = plays.merge(characters_plays.groupby('play_id')['character_id'].apply(list).reset_index(), how='left')\n",
    "# images\n",
    "plays = plays.merge(plays_images.groupby('play_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "# productions\n",
    "plays = plays.merge(performances.groupby('play_id')['production_id'].apply(list).reset_index(), how='left')\n",
    "# performances\n",
    "plays = plays.merge(performances.groupby('play_id')['performance_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = productions.drop('performance_num',1)\n",
    "# images\n",
    "productions = productions.merge(productions_images.groupby('production_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "# performances\n",
    "productions = productions.merge(performances.groupby('production_id')['performance_id'].apply(list).reset_index(), how='left')\n",
    "# plays\n",
    "productions = productions.merge(performances.groupby('production_id')['play_id'].apply(list).reset_index(), how='left')\n",
    "productions = productions[['production_id','dates','place','label_eng','image_id','performance_id','play_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags['notes'] = tags['notes'].replace({r'\\n': ''}, regex=True)\n",
    "tags = tags.merge(tags_images.groupby('tag_id')['image_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "performers = performers[['performer_id','name_proper','alt_name','name_ka','alt_name_ka','specialty','dates','notes']]\n",
    "# add images\n",
    "performers = performers.merge(performers_images.groupby('performer_id')['image_id'].apply(list).reset_index(), how='left')\n",
    "# add performances as musician \n",
    "### make a join table from pscenes\n",
    "performer_as_musician = pscenes[['musician_id','performance_id']].dropna(how='any').rename(columns={'musician_id':'performer_id','performance_id':'musician_perf_id'})\n",
    "performer_as_musician = performer_as_musician.groupby('musician_perf_id').performer_id.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)\n",
    "performer_as_musician.columns = ['musician_perf_id','performer_id']\n",
    "performer_as_musician.drop_duplicates(inplace=True)\n",
    "### add performances\n",
    "performers = performers.merge(performer_as_musician.groupby('performer_id')['musician_perf_id'].apply(list).reset_index(), how='left')\n",
    "# add performances as narrator\n",
    "### make a join table from pscenes\n",
    "performer_as_narrator = pscenes[['narrator_id','performance_id']].dropna(how='any').rename(columns={'narrator_id':'performer_id','performance_id':'narrator_perf_id'})\n",
    "performer_as_narrator = performer_as_narrator.groupby('narrator_perf_id').performer_id.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)\n",
    "performer_as_narrator.columns = ['narrator_perf_id','performer_id']\n",
    "performer_as_narrator.drop_duplicates(inplace=True)\n",
    "### add performances\n",
    "performers = performers.merge(performer_as_narrator.groupby('performer_id')['narrator_perf_id'].apply(list).reset_index(), how='left')\n",
    "# add performances as shamisen player\n",
    "### make a join table from pscenes\n",
    "performer_as_shamisen = pscenes[['shamisen_id','performance_id']].dropna(how='any').rename(columns={'shamisen_id':'performer_id','performance_id':'shamisen_perf_id'})\n",
    "performer_as_shamisen = performer_as_shamisen.groupby('shamisen_perf_id').performer_id.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)\n",
    "performer_as_shamisen.columns = ['shamisen_perf_id','performer_id']\n",
    "performer_as_shamisen.drop_duplicates(inplace=True)\n",
    "### add performances\n",
    "performers = performers.merge(performer_as_shamisen.groupby('performer_id')['shamisen_perf_id'].apply(list).reset_index(), how='left')\n",
    "# add performances as puppeteer and kashira used\n",
    "### make a join table from pscenes\n",
    "spucks_performances = pscenes[['spuck_id','performance_id']].dropna(how='any').rename(columns={'performance_id':'puppeteer_perf_id'})\n",
    "spucks_performances = spucks_performances.groupby('puppeteer_perf_id').spuck_id.apply(lambda x: pd.DataFrame(x.values[0])).reset_index().drop('level_1', axis = 1)\n",
    "spucks_performances.columns = ['puppeteer_perf_id','spuck_id']\n",
    "spucks_performances.drop_duplicates(inplace=True)\n",
    "### make join table with performer_id, kashira_id, and puppeteer_perf_id\n",
    "xtra_spucks = spucks[['spuck_id','pscene_id','puppeteer_id','kashira_id']].rename(columns={'puppeteer_id':'performer_id'})\n",
    "xtra_spucks = xtra_spucks.merge(spucks_performances, on='spuck_id', how='left').drop('spuck_id',1).drop('pscene_id',1)\n",
    "### add performances\n",
    "performer_as_puppeteer = xtra_spucks[['performer_id','puppeteer_perf_id']].dropna(how='any').drop_duplicates()\n",
    "performers = performers.merge(performer_as_puppeteer.groupby('performer_id')['puppeteer_perf_id'].apply(list).reset_index(), how='left')\n",
    "### add kashira\n",
    "performer_puppets = xtra_spucks[['performer_id','kashira_id']].dropna(how='any').drop_duplicates()\n",
    "performers = performers.merge(performer_puppets.groupby('performer_id')['kashira_id'].apply(list).reset_index(), how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to CSV and JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace descriptive id (used for joins) with generic id\n",
    "authors.rename(columns={'author_id':'id'}, inplace=True)\n",
    "characters.rename(columns={'character_id':'id'}, inplace=True)\n",
    "images.rename(columns={'image_id':'id'}, inplace=True)\n",
    "kashira.rename(columns={'kashira_id':'id'}, inplace=True)\n",
    "performances.rename(columns={'performance_id':'id'}, inplace=True)\n",
    "performers.rename(columns={'performer_id':'id'}, inplace=True)\n",
    "plays.rename(columns={'play_id':'id'}, inplace=True)\n",
    "productions.rename(columns={'production_id':'id'}, inplace=True)\n",
    "pscenes.rename(columns={'pscene_id':'id'}, inplace=True)\n",
    "spucks.rename(columns={'spuck_id':'id'}, inplace=True)\n",
    "tags.rename(columns={'tag_id':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data as CSV\n",
    "authors.to_csv('authors_full.csv', encoding='utf8', index=False)\n",
    "characters.to_csv('characters_full.csv', encoding='utf8', index=False)\n",
    "images.to_csv('images_full.csv', encoding='utf8', index=False)\n",
    "kashira.to_csv('kashira_full.csv', encoding='utf8', index=False)\n",
    "performances.to_csv('performances_full.csv', encoding='utf8', index=False)\n",
    "performers.to_csv('performers_full.csv', encoding='utf8', index=False)\n",
    "plays.to_csv('plays_full.csv', encoding='utf8', index=False)\n",
    "productions.to_csv('productions_full.csv', encoding='utf8', index=False)\n",
    "pscenes.to_csv('pscenes_full.csv', encoding='utf8', index=False)\n",
    "spucks.to_csv('spucks_full.csv', encoding='utf8', index=False)\n",
    "tags.to_csv('tags_full.csv', encoding='utf8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export data as JSON\n",
    "authors.to_json('authors_full.json', orient=\"records\", force_ascii=False)\n",
    "characters.to_json('characters_full.json', orient=\"records\", force_ascii=False)\n",
    "creators.to_json('creators_full.json', orient=\"records\", force_ascii=False)\n",
    "images.to_json('images_full.json', orient=\"records\", force_ascii=False)\n",
    "kashira.to_json('kashira_full.json', orient=\"records\", force_ascii=False)\n",
    "performances.to_json('performances_full.json', orient=\"records\", force_ascii=False)\n",
    "performers.to_json('performers_full.json', orient=\"records\", force_ascii=False)\n",
    "plays.to_json('plays_full.json', orient=\"records\", force_ascii=False)\n",
    "productions.to_json('productions_full.json', orient=\"records\", force_ascii=False)\n",
    "pscenes.to_json('pscenes_full.json', orient=\"records\", force_ascii=False)\n",
    "spucks.to_json('spucks_full.json', orient=\"records\", force_ascii=False)\n",
    "tags.to_json('tags_full.json', orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
